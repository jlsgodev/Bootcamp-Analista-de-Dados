{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8mszC82jLpCh",
        "jupyter": {
          "is_executing": true
        }
      },
      "outputs": [],
      "source": [
        "# Importação da biblioteca pandas\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-08-29T18:52:49.193869Z",
          "start_time": "2024-08-29T18:52:02.857555Z"
        },
        "id": "hz3NhJDsqVP7"
      },
      "outputs": [],
      "source": [
        "# Instalação dos requisitos para o PySpark\n",
        "!sudo apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://archive.apache.org/dist/spark/spark-3.1.1/spark-3.1.1-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.1.1-bin-hadoop3.2.tgz\n",
        "!pip install -q findspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-08-29T19:01:23.312005Z",
          "start_time": "2024-08-29T19:01:19.098317Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QiJA0v2HNSSV",
        "outputId": "2a2dd7ed-d77f-4d27-96b6-e57ea45f0604"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.2.tar.gz (317.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.3/317.3 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.2-py2.py3-none-any.whl size=317812365 sha256=ca5cba904414abfa21b30eafdebfdab73cb40d49d546377fd561d53f2286b2d5\n",
            "  Stored in directory: /root/.cache/pip/wheels/34/34/bd/03944534c44b677cd5859f248090daa9fb27b3c8f8e5f49574\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.2\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OnvBVPCYTKuK",
        "outputId": "04244200-c7db-4d26-e0a8-3d045734c44a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.10/dist-packages (3.1.5)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl) (1.1.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install openpyxl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZupf7VlFD__"
      },
      "source": [
        "### 1. Análise de Consistência de Dados: Identificar e corrigir inconsistências nos valores de \"Área\" e \"Status de Emprego\" (e.g., diferenças de maiúsculas/minúsculas)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-08-29T19:12:17.646748Z",
          "start_time": "2024-08-29T19:12:17.494486Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6sswD5yA-hZ",
        "outputId": "34c53c46-04a5-4294-e85b-3546cc47376a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+--------------+-----+----------+-------+-------------------+-----------------+\n",
            "|  ID|          Nome|Idade|      Área|Salário|Data de Contratação|Status de Emprego|\n",
            "+----+--------------+-----+----------+-------+-------------------+-----------------+\n",
            "| 1.0|    João Silva| 29.0|Financeiro|   5500|         01/02/2020|            Ativo|\n",
            "| 2.0|   Maria Souza| 30.0|        RH|   4800|         15-03-2019|            ativo|\n",
            "| 3.0|Carlos Pereira| NULL| Finaceiro|   6200|         2020/04/01|            Ativo|\n",
            "| 4.0|     Ana Clara| 27.0| Marketing|   4800|         12/06/2018|            Ativo|\n",
            "| 5.0|  Fabio Santos| 31.0|          |   5500|         20-11-2017|            ativo|\n",
            "| 6.0|   Sandra Lima| 28.0|        RH|   NULL|         05-05-2020|            Ativo|\n",
            "| 7.0|    José Alves| 34.0| Marketing|   5400|         2018/02/01|          inativo|\n",
            "| 8.0| Luciana Costa| 30.0|Financeiro|R$ 5200|         01.01.2019|            Ativo|\n",
            "| 9.0| Paulo Ricardo| NULL| Finaceiro|   6100|         12/12/2020|          Inativo|\n",
            "|10.0| Fernanda Dias| 29.0|        RH|   4800|                   |            Ativo|\n",
            "| 1.0|    João Silva| 29.0|Financeiro|   5500|         01/02/2020|            Ativo|\n",
            "|NULL|          NULL| NULL|      NULL|   NULL|               NULL|             NULL|\n",
            "|NULL|          NULL| NULL|      NULL|   NULL|               NULL|             NULL|\n",
            "|NULL|          NULL| NULL|      NULL|   NULL|               NULL|             NULL|\n",
            "|NULL|          NULL| NULL|      NULL|   NULL|               NULL|             NULL|\n",
            "|NULL|          NULL| NULL|      NULL|   NULL|               NULL|             NULL|\n",
            "|NULL|          NULL| NULL|      NULL|   NULL|               NULL|             NULL|\n",
            "|NULL|          NULL| NULL|      NULL|   NULL|               NULL|             NULL|\n",
            "|NULL|          NULL| NULL|      NULL|   NULL|               NULL|             NULL|\n",
            "|NULL|          NULL| NULL|      NULL|   NULL|               NULL|             NULL|\n",
            "+----+--------------+-----+----------+-------+-------------------+-----------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import functions as F\n",
        "\n",
        "# Configurar a sessão Spark com o pacote spark-excel\n",
        "spark = SparkSession.builder \\\n",
        "    .appName('Ler XLSX com PySpark') \\\n",
        "    .config('spark.jars.packages', 'com.crealytics:spark-excel_2.12:0.13.5') \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Caminho para o arquivo Excel\n",
        "file_path = '/content/base_suja.xlsx'\n",
        "\n",
        "# Ler o arquivo Excel\n",
        "df = spark.read.format('com.crealytics.spark.excel') \\\n",
        "    .option('header', 'true') \\\n",
        "    .option('inferSchema', 'true') \\\n",
        "    .option('dataAddress', \"'Planilha1'!A1\") \\\n",
        "    .load(file_path)\n",
        "\n",
        "# Exibir  DataFrame\n",
        "df.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Alterar minusculas para maiusculas nas tabelas 'Área' e 'Status de Emprego'\n",
        "df = df.withColumn('Área', F.upper(F.col('Área')))\n",
        "df = df.withColumn('Status de Emprego', F.upper(F.col('Status de Emprego')))\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5uAnALasx3Z",
        "outputId": "d6ca327a-275f-4d23-e81d-e35909e10534"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+--------------+-----+----------+-------+-------------------+-----------------+\n",
            "|  ID|          Nome|Idade|      Área|Salário|Data de Contratação|Status de Emprego|\n",
            "+----+--------------+-----+----------+-------+-------------------+-----------------+\n",
            "| 1.0|    João Silva| 29.0|FINANCEIRO|   5500|         01/02/2020|            ATIVO|\n",
            "| 2.0|   Maria Souza| 30.0|        RH|   4800|         15-03-2019|            ATIVO|\n",
            "| 3.0|Carlos Pereira| NULL| FINACEIRO|   6200|         2020/04/01|            ATIVO|\n",
            "| 4.0|     Ana Clara| 27.0| MARKETING|   4800|         12/06/2018|            ATIVO|\n",
            "| 5.0|  Fabio Santos| 31.0|          |   5500|         20-11-2017|            ATIVO|\n",
            "| 6.0|   Sandra Lima| 28.0|        RH|   NULL|         05-05-2020|            ATIVO|\n",
            "| 7.0|    José Alves| 34.0| MARKETING|   5400|         2018/02/01|          INATIVO|\n",
            "| 8.0| Luciana Costa| 30.0|FINANCEIRO|R$ 5200|         01.01.2019|            ATIVO|\n",
            "| 9.0| Paulo Ricardo| NULL| FINACEIRO|   6100|         12/12/2020|          INATIVO|\n",
            "|10.0| Fernanda Dias| 29.0|        RH|   4800|                   |            ATIVO|\n",
            "| 1.0|    João Silva| 29.0|FINANCEIRO|   5500|         01/02/2020|            ATIVO|\n",
            "|NULL|          NULL| NULL|      NULL|   NULL|               NULL|             NULL|\n",
            "|NULL|          NULL| NULL|      NULL|   NULL|               NULL|             NULL|\n",
            "|NULL|          NULL| NULL|      NULL|   NULL|               NULL|             NULL|\n",
            "|NULL|          NULL| NULL|      NULL|   NULL|               NULL|             NULL|\n",
            "|NULL|          NULL| NULL|      NULL|   NULL|               NULL|             NULL|\n",
            "|NULL|          NULL| NULL|      NULL|   NULL|               NULL|             NULL|\n",
            "|NULL|          NULL| NULL|      NULL|   NULL|               NULL|             NULL|\n",
            "|NULL|          NULL| NULL|      NULL|   NULL|               NULL|             NULL|\n",
            "|NULL|          NULL| NULL|      NULL|   NULL|               NULL|             NULL|\n",
            "+----+--------------+-----+----------+-------+-------------------+-----------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mH_pDYOFXjk"
      },
      "source": [
        "### 2. Limpeza de Dados Faltantes: Detectar e tratar os valores ausentes na coluna \"Idade\" e \"Área\".\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-08-29T19:04:41.116565Z",
          "start_time": "2024-08-29T19:04:38.372865Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xyrvKqx_Faec",
        "outputId": "dae4c6be-7009-40c6-e2a5-42dd3799d3a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+--------------+-----+------------+-------+-------------------+-----------------+\n",
            "|  ID|          Nome|Idade|        Área|Salário|Data de Contratação|Status de Emprego|\n",
            "+----+--------------+-----+------------+-------+-------------------+-----------------+\n",
            "| 8.0| Luciana Costa| 30.0|  FINANCEIRO|R$ 5200|         01.01.2019|            ATIVO|\n",
            "|10.0| Fernanda Dias| 29.0|          RH|   4800|                   |            ATIVO|\n",
            "| 5.0|  Fabio Santos| 31.0|DESCONHECIDA|   5500|         20-11-2017|            ATIVO|\n",
            "| 2.0|   Maria Souza| 30.0|          RH|   4800|         15-03-2019|            ATIVO|\n",
            "| 7.0|    José Alves| 34.0|   MARKETING|   5400|         2018/02/01|          INATIVO|\n",
            "| 4.0|     Ana Clara| 27.0|   MARKETING|   4800|         12/06/2018|            ATIVO|\n",
            "| 1.0|    João Silva| 29.0|  FINANCEIRO|   5500|         01/02/2020|            ATIVO|\n",
            "| 3.0|Carlos Pereira| 30.0|  FINANCEIRO|   6200|         2020/04/01|            ATIVO|\n",
            "| 6.0|   Sandra Lima| 28.0|          RH|   NULL|         05-05-2020|            ATIVO|\n",
            "| 9.0| Paulo Ricardo| 30.0|  FINANCEIRO|   6100|         12/12/2020|          INATIVO|\n",
            "+----+--------------+-----+------------+-------+-------------------+-----------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import functions as F\n",
        "\n",
        "# Remover linhas duplicadas como exemplo João Silva\n",
        "df = df.dropDuplicates()\n",
        "\n",
        "# Remover linhas completamente vazias (todos os campos NULL)\n",
        "df = df.na.drop(how='all')\n",
        "\n",
        "# Substituir valores vazios na coluna 'Área' por 'DESCONHECIDA'\n",
        "df = df.withColumn('Área', F.when(F.col('Área') == '', 'DESCONHECIDA').otherwise(F.col('Área')))\n",
        "\n",
        "# Corrigir valores da coluna 'Área' de 'FINACEIRO' para 'FINANCEIRO'\n",
        "df = df.withColumn('Área', F.when(F.col('Área') == 'FINACEIRO', 'FINANCEIRO').otherwise(F.col('Área')))\n",
        "\n",
        "# Calcular a média da coluna 'Idade', se houver valores não nulos\n",
        "media_idade = df.agg(F.mean(F.col('Idade'))).first()[0]\n",
        "\n",
        "# Preencher valores nulos na coluna 'Idade' com a média calculada\n",
        "df = df.withColumn('Idade', F.when(F.col('Idade').isNull(), media_idade).otherwise(F.col('Idade')))\n",
        "\n",
        "# Arredondar a coluna 'Idade'\n",
        "df = df.withColumn('Idade', F.round(F.col('Idade'), 0))\n",
        "\n",
        "# Exibir o DataFrame final corrigido\n",
        "df.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2zWLGEXFa4K"
      },
      "source": [
        "### 3. Distribuição de Idade: Analisar a distribuição da idade dos funcionários por departamento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-08-29T19:16:56.273679Z",
          "start_time": "2024-08-29T19:16:53.563909Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lplkYd4xqVP-",
        "outputId": "ab601ba0-82b5-4ed3-e159-8b8d651bf517"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+--------+-----------+------------+------------+\n",
            "|        Área|Contagem|Média_Idade|Idade_Mínima|Idade_Máxima|\n",
            "+------------+--------+-----------+------------+------------+\n",
            "|   MARKETING|       2|       30.5|        27.0|        34.0|\n",
            "|          RH|       3|       29.0|        28.0|        30.0|\n",
            "|DESCONHECIDA|       1|       31.0|        31.0|        31.0|\n",
            "|  FINANCEIRO|       4|       29.8|        29.0|        30.0|\n",
            "+------------+--------+-----------+------------+------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import functions as F\n",
        "\n",
        "# Calcular a média, min e max da coluna 'Idade' agrupando por 'Área'\n",
        "df_idade_distribuicao = df.groupBy('Área') \\\n",
        "    .agg(F.count('Idade').alias('Contagem'),\n",
        "         F.round(F.mean('Idade'), 1).alias('Média_Idade'),\n",
        "         F.min('Idade').alias('Idade_Mínima'),\n",
        "         F.max('Idade').alias('Idade_Máxima'))\n",
        "\n",
        "# Exibir a distribuição de idades por área\n",
        "df_idade_distribuicao.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9YOmfPvFfUG"
      },
      "source": [
        "### 4. Salário por Departamento: Calcular a média, mediana e desvio padrão dos salários por departamento.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-08-29T19:22:08.870733Z",
          "start_time": "2024-08-29T19:22:07.286396Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bk0n5F0UFi9k",
        "outputId": "a3f733d6-21bb-4ab3-ef3f-833c95107af0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+-------------+---------------+---------------------+\n",
            "|        Área|Media_Salario|Mediana_Salario|Desvio_Padrao_Salario|\n",
            "+------------+-------------+---------------+---------------------+\n",
            "|   MARKETING|       5100.0|         4800.0|                424.3|\n",
            "|          RH|       4800.0|         4800.0|                  0.0|\n",
            "|DESCONHECIDA|       5500.0|         5500.0|                 NULL|\n",
            "|  FINANCEIRO|       5750.0|         5500.0|                479.6|\n",
            "+------------+-------------+---------------+---------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from pyspark.sql import functions as F\n",
        "\n",
        "# Renomear a coluna 'Salário' para evitar problemas\n",
        "df = df.withColumnRenamed('Salário', 'Salario')\n",
        "\n",
        "# Remover 'R$' e converter a coluna 'Salario' para numérico\n",
        "df = df.withColumn(\n",
        "    'Salario',\n",
        "    F.regexp_replace('Salario', 'R\\\\$', '').cast('double')\n",
        ")\n",
        "\n",
        "# Calcular estatísticas descritivas dos salários por departamento\n",
        "estatisticas_salario = df.groupBy('Área').agg(\n",
        "    F.mean('Salario').alias('Media_Salario'),\n",
        "    F.expr('percentile_approx(Salario, 0.5)').alias('Mediana_Salario'),\n",
        "    F.round(F.stddev('Salario'), 1).alias('Desvio_Padrao_Salario')\n",
        ")\n",
        "\n",
        "# Resultados\n",
        "estatisticas_salario.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knwMdAArFjaD"
      },
      "source": [
        "### 5. Análise de Outliers: Identificar salários que estão fora do padrão (outliers) para cada departamento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BjneMjooqVP-",
        "outputId": "71df6d16-c01c-4308-d1a3-16db30bf9117"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+--------------+-----+------------+-------+-------------------+-----------------+-------+\n",
            "|  ID|          Nome|Idade|        Área|Salario|Data de Contratação|Status de Emprego|Z_Score|\n",
            "+----+--------------+-----+------------+-------+-------------------+-----------------+-------+\n",
            "| 5.0|  Fabio Santos| 31.0|DESCONHECIDA| 5500.0|         20-11-2017|            ATIVO|   NULL|\n",
            "| 8.0| Luciana Costa| 30.0|  FINANCEIRO| 5200.0|         01.01.2019|            ATIVO|  -1.15|\n",
            "| 1.0|    João Silva| 29.0|  FINANCEIRO| 5500.0|         01/02/2020|            ATIVO|  -0.52|\n",
            "| 3.0|Carlos Pereira| 30.0|  FINANCEIRO| 6200.0|         2020/04/01|            ATIVO|   0.94|\n",
            "| 9.0| Paulo Ricardo| 30.0|  FINANCEIRO| 6100.0|         12/12/2020|          INATIVO|   0.73|\n",
            "| 7.0|    José Alves| 34.0|   MARKETING| 5400.0|         2018/02/01|          INATIVO|   0.71|\n",
            "| 4.0|     Ana Clara| 27.0|   MARKETING| 4800.0|         12/06/2018|            ATIVO|  -0.71|\n",
            "|10.0| Fernanda Dias| 29.0|          RH| 4800.0|                   |            ATIVO|   NULL|\n",
            "| 2.0|   Maria Souza| 30.0|          RH| 4800.0|         15-03-2019|            ATIVO|   NULL|\n",
            "| 6.0|   Sandra Lima| 28.0|          RH| 4800.0|         05-05-2020|            ATIVO|   NULL|\n",
            "+----+--------------+-----+------------+-------+-------------------+-----------------+-------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql.window import Window\n",
        "\n",
        "# Remover 'R$' e converter a coluna 'Salario' para numérico\n",
        "df = df.withColumn(\n",
        "    'Salario',\n",
        "    F.regexp_replace('Salario', 'R\\\\$', '').cast('double')\n",
        ")\n",
        "\n",
        "# Adicionar o salário de Sandra Lima\n",
        "df = df.withColumn(\n",
        "    'Salario',\n",
        "    F.when(F.col('Nome') == 'Sandra Lima',  4800.0).otherwise(F.col('Salario'))\n",
        ")\n",
        "\n",
        "# Definir a janela por departamento\n",
        "windowSpec = Window.partitionBy('Área')\n",
        "\n",
        "# Calcular Z-Score e arredondar\n",
        "df_outliers = df.withColumn(\n",
        "    'Z_Score',\n",
        "    F.round((F.col('Salario') - F.avg('Salario').over(windowSpec)) / F.stddev('Salario').over(windowSpec), 2)\n",
        ")\n",
        "\n",
        "# Mostrar todas as linhas com suas estatísticas\n",
        "df_outliers.show()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "McFtq5-xFp-I"
      },
      "source": [
        "### 6. Correlação Idade-Salário: Analisar a correlação entre idade e salário dos funcionários.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kYkWLjwwFrA5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f531364c-4c87-4578-a9da-fcb603c7b4bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correlação entre Idade e Salário: 0.38106375880210946\n"
          ]
        }
      ],
      "source": [
        "# Calcular a correlação entre 'Idade' e 'Salário' usando o método de Pearson (padrão)\n",
        "correlacao = df.stat.corr('Idade', 'Salario')\n",
        "print(f'Correlação entre Idade e Salário: {correlacao}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJ0NGw0wFrhq"
      },
      "source": [
        "### 7. Tempo de Casa: Calcular o tempo de contratação dos funcionários e categorizá-los em grupos (e.g., 1-3 anos, 4-6 anos, etc.)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EXN_MZmMqVP_",
        "outputId": "69cd4fd5-6dfb-478a-dae6-8e771c9b43b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+-------------------+------------------+-------------------+\n",
            "|          Nome|Data_de_Contratação|     Tempo_de_Casa|   Grupo_Tempo_Casa|\n",
            "+--------------+-------------------+------------------+-------------------+\n",
            "| Luciana Costa|         01/01/2019| 5.670088980150582|           3-6 anos|\n",
            "| Fernanda Dias|               NULL|              NULL|Data não disponível|\n",
            "|  Fabio Santos|         20/11/2017| 6.784394250513347|            6+ anos|\n",
            "|   Maria Souza|         15/03/2019| 5.470225872689938|           3-6 anos|\n",
            "|    José Alves|         01/02/2018| 6.584531143052704|            6+ anos|\n",
            "|     Ana Clara|         12/06/2018| 6.225872689938399|            6+ anos|\n",
            "|    João Silva|         01/02/2020|  4.58590006844627|           3-6 anos|\n",
            "|Carlos Pereira|         01/04/2020| 4.421629021218344|           3-6 anos|\n",
            "|   Sandra Lima|         05/05/2020| 4.328542094455853|           3-6 anos|\n",
            "| Paulo Ricardo|         12/12/2020|3.7234770704996576|           3-6 anos|\n",
            "+--------------+-------------------+------------------+-------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import udf, col, to_date, datediff, current_date, when, date_format, lit\n",
        "from pyspark.sql.types import StringType\n",
        "from datetime import datetime\n",
        "\n",
        "# Função para padronizar datas\n",
        "def padronizar_data(data):\n",
        "    formatos = ['%d/%m/%Y', '%d-%m-%Y', '%Y/%m/%d', '%d.%m.%Y']\n",
        "    for formato in formatos:\n",
        "        try:\n",
        "            return datetime.strptime(data, formato).strftime('%d/%m/%Y')\n",
        "        except:\n",
        "            continue\n",
        "    return None\n",
        "\n",
        "# Registrar a função UDF\n",
        "padronizar_data_udf = udf(padronizar_data, StringType())\n",
        "\n",
        "# Aplicar a função ao DataFrame\n",
        "df = df.withColumn('Data de Contratação', padronizar_data_udf(col('Data de Contratação')))\n",
        "\n",
        "# Calcular a data de contratação e o tempo de casa em anos completos (arredondados)\n",
        "df_tempo_casa = df.withColumn('Data_de_Contratação', to_date(col('Data de Contratação'), 'dd/MM/yyyy')) \\\n",
        "    .withColumn('Tempo_de_Casa', datediff(current_date(), col('Data_de_Contratação')) / 365.25) \\\n",
        "    .withColumn('Grupo_Tempo_Casa',\n",
        "                when(col('Tempo_de_Casa').isNull(), 'Data não disponível')\n",
        "                .when(col('Tempo_de_Casa') < 1, 'Menos de 1 ano')\n",
        "                .when((col('Tempo_de_Casa') >= 1) & (col('Tempo_de_Casa') < 3), '1-3 anos')\n",
        "                .when((col('Tempo_de_Casa') >= 3) & (col('Tempo_de_Casa') < 6), '3-6 anos')\n",
        "                .otherwise('6+ anos')) \\\n",
        "    .withColumn('Data_de_Contratação', date_format(col('Data_de_Contratação'), 'dd/MM/yyyy'))\n",
        "\n",
        "df_tempo_casa.select('Nome', 'Data_de_Contratação', 'Tempo_de_Casa', 'Grupo_Tempo_Casa').show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xw2elR4nFvaK"
      },
      "source": [
        "### 8. Análise de Rotatividade: Identificar padrões entre os funcionários que estão ativos versus os que não estão."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Identificar padrões  entre funcionários\n",
        "df_rotatividade = df.groupBy('Status de Emprego') \\\n",
        "    .agg(F.count('*').alias('Contagem'),\n",
        "         F.round(F.avg('Idade'), 1).alias('Média_Idade'),\n",
        "         F.avg('Salario').alias('Média_Salário'))\n",
        "\n",
        "df_rotatividade.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lkF6y2iuOWyy",
        "outputId": "c4093b7b-b53d-478a-c2b6-b101382e16c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+--------+-----------+-------------+\n",
            "|Status de Emprego|Contagem|Média_Idade|Média_Salário|\n",
            "+-----------------+--------+-----------+-------------+\n",
            "|          INATIVO|       2|       32.0|       5750.0|\n",
            "|            ATIVO|       8|       29.3|       5200.0|\n",
            "+-----------------+--------+-----------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "142s-af0FzlX"
      },
      "source": [
        "### 9. Análise de Desempenho por Data de Contratação: Verificar se existe uma correlação entre o ano de contratação e o nível de salário."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M5hN9B7hF31j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42cdbf3f-1599-4b4f-a039-92d540191837"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+-------------+\n",
            "|Ano_Contratacao|Media_Salario|\n",
            "+---------------+-------------+\n",
            "|           2017|       5500.0|\n",
            "|           2018|       5100.0|\n",
            "|           2019|       5000.0|\n",
            "|           2020|       5650.0|\n",
            "|   Desconhecido|       4800.0|\n",
            "+---------------+-------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql.functions import udf, col\n",
        "from pyspark.sql.types import StringType\n",
        "\n",
        "# Extrair o ano da data de contratação da coluna 'Data de Contratação'\n",
        "padronizar_data_udf = udf(lambda data: data.split('/')[-1] if data is not None else 'Desconhecido', StringType())\n",
        "df = df.withColumn('Ano_Contratacao', padronizar_data_udf(col('Data de Contratação')))\n",
        "\n",
        "# Calcular a média de salário por ano de contratação\n",
        "df_salario_ano = df.groupBy('Ano_Contratacao').agg(F.mean('Salario').alias('Media_Salario')).sort('Ano_Contratacao')\n",
        "df_salario_ano.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1o1EaIEjF4H-"
      },
      "source": [
        "### 10. Histograma de Salário: Criar um histograma de salários para visualizar a distribuição geral."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt  # Importar a biblioteca de visualização matplotlib que será usada para criar o histograma\n",
        "from pyspark.sql.functions import col # Importar a função 'col' para referenciar colunas\n",
        "\n",
        "# Converter a coluna 'Salário' para numérico, removendo qualquer caractere não numérico\n",
        "df_hist_salario = df.withColumn('Salario', col('Salario').cast('double'))\n",
        "\n",
        "# Verificar se a conversão foi bem-sucedida\n",
        "df_hist_salario.select('Salario').show()\n",
        "\n",
        "# Histograma de Salários\n",
        "hist_data = df_hist_salario.select('Salario').rdd.flatMap(lambda x: x).histogram(20)\n",
        "\n",
        "# Valores e contagens do histograma de salários\n",
        "valores, contagens = hist_data\n",
        "# Plotar o histograma de salários\n",
        "plt.bar(valores[:-1], contagens, width=valores[1] - valores[0])\n",
        "plt.xlabel('Salário')\n",
        "plt.ylabel('Frequência')\n",
        "plt.title('Histograma de Salários')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 732
        },
        "id": "_eF1EgPn386C",
        "outputId": "4f4cb61f-c39b-4641-c764-c2eb11ecc181"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+\n",
            "|Salario|\n",
            "+-------+\n",
            "| 5200.0|\n",
            "| 4800.0|\n",
            "| 5500.0|\n",
            "| 4800.0|\n",
            "| 5400.0|\n",
            "| 4800.0|\n",
            "| 5500.0|\n",
            "| 6200.0|\n",
            "| 4800.0|\n",
            "| 6100.0|\n",
            "+-------+\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3ihSfh2F8ZS"
      },
      "source": [
        "### 11. Análise de Frequência: Quantificar a frequência dos nomes dos funcionários para identificar nomes comuns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "45BVKL4mGAa5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76cd5b49-9e80-4732-88b1-360010578059"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+-----+\n",
            "|          Nome|count|\n",
            "+--------------+-----+\n",
            "|     Ana Clara|    1|\n",
            "| Paulo Ricardo|    1|\n",
            "| Fernanda Dias|    1|\n",
            "|   Sandra Lima|    1|\n",
            "|    José Alves|    1|\n",
            "| Luciana Costa|    1|\n",
            "|  Fabio Santos|    1|\n",
            "|Carlos Pereira|    1|\n",
            "|    João Silva|    1|\n",
            "|   Maria Souza|    1|\n",
            "+--------------+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import col   # Importar a função 'col' que é usada para referenciar colunas\n",
        "\n",
        "# Agrupar por 'Nome' e contar a frequência de cada nome\n",
        "nome_frequencia = df.groupBy('Nome').count()\n",
        "\n",
        "# Ordenar por frequência decrescente\n",
        "nome_frequencia = nome_frequencia.orderBy(col('count').desc())\n",
        "\n",
        "# Show the frequency of names\n",
        "nome_frequencia.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WiXFA7waGAqU"
      },
      "source": [
        "### 12. Agrupamento de Departamentos: Analisar o impacto do departamento na variação salarial e na distribuição de idade."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_departamento = df.groupBy('Área') \\\n",
        "    .agg(F.count('Salario').alias('Contagem_Funcionários'),\n",
        "         F.round(F.mean('Salario'), 2).alias('Média_Salário'),\n",
        "         F.round(F.stddev('Salario'), 2).alias('Desvio_Padrão_Salário'),\n",
        "         F.round(F.mean('Idade'), 2).alias('Média_Idade'),\n",
        "         F.round(F.stddev('Idade'), 2).alias('Desvio_Padrão_Idade'))\n",
        "\n",
        "# Exibir o DataFrame\n",
        "df_departamento.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNZqRveO5mqO",
        "outputId": "ceb00b24-c798-4b10-f991-1bcb7b2151bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+---------------------+-------------+---------------------+-----------+-------------------+\n",
            "|        Área|Contagem_Funcionários|Média_Salário|Desvio_Padrão_Salário|Média_Idade|Desvio_Padrão_Idade|\n",
            "+------------+---------------------+-------------+---------------------+-----------+-------------------+\n",
            "|   MARKETING|                    2|       5100.0|               424.26|       30.5|               4.95|\n",
            "|          RH|                    3|       4800.0|                  0.0|       29.0|                1.0|\n",
            "|DESCONHECIDA|                    1|       5500.0|                 NULL|       31.0|               NULL|\n",
            "|  FINANCEIRO|                    4|       5750.0|               479.58|      29.75|                0.5|\n",
            "+------------+---------------------+-------------+---------------------+-----------+-------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5hfVHzXGF_h"
      },
      "source": [
        "### 13. Normalização de Dados: Normalizar o salário e idade para comparações entre diferentes departamentos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ac7bnbbCGHNR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c14c7f89-a555-4e86-c9ae-ad2510260b86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+------------+-------+-----+-------------------------+\n",
            "|          Nome|        Área|Salario|Idade|caracteristicas_escaladas|\n",
            "+--------------+------------+-------+-----+-------------------------+\n",
            "| Luciana Costa|  FINANCEIRO| 5200.0| 30.0|     [0.28571428571428...|\n",
            "| Fernanda Dias|          RH| 4800.0| 29.0|     [0.0,0.2857142857...|\n",
            "|  Fabio Santos|DESCONHECIDA| 5500.0| 31.0|     [0.5,0.5714285714...|\n",
            "|   Maria Souza|          RH| 4800.0| 30.0|     [0.0,0.4285714285...|\n",
            "|    José Alves|   MARKETING| 5400.0| 34.0|     [0.42857142857142...|\n",
            "|     Ana Clara|   MARKETING| 4800.0| 27.0|                (2,[],[])|\n",
            "|    João Silva|  FINANCEIRO| 5500.0| 29.0|     [0.5,0.2857142857...|\n",
            "|Carlos Pereira|  FINANCEIRO| 6200.0| 30.0|     [1.0,0.4285714285...|\n",
            "|   Sandra Lima|          RH| 4800.0| 28.0|     [0.0,0.1428571428...|\n",
            "| Paulo Ricardo|  FINANCEIRO| 6100.0| 30.0|     [0.92857142857142...|\n",
            "+--------------+------------+-------+-----+-------------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.ml.feature import MinMaxScaler, VectorAssembler\n",
        "\n",
        "# Criar um VectorAssembler para combinar as colunas 'Salário' e 'Idade' em uma única coluna 'caracteristicas'\n",
        "montador = VectorAssembler(inputCols=['Salario', 'Idade'], outputCol='caracteristicas')\n",
        "\n",
        "# Aplicar o VectorAssembler ao DataFrame\n",
        "df_montado = montador.transform(df)\n",
        "\n",
        "# Inicializar o MinMaxScaler\n",
        "escalador = MinMaxScaler(inputCol='caracteristicas', outputCol='caracteristicas_escaladas')\n",
        "\n",
        "# Ajustar e transformar os dados\n",
        "modelo_escalador = escalador.fit(df_montado)\n",
        "df_normalizado = modelo_escalador.transform(df_montado)\n",
        "\n",
        "# Mostrar o DataFrame com os dados normalizados\n",
        "df_normalizado.select('Nome', 'Área', 'Salario', 'Idade', 'caracteristicas_escaladas').show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDPGuQ8iGJEw"
      },
      "source": [
        "14. Proporção de Gêneros: Analisar a proporção de gêneros entre os funcionários, caso houvesse uma coluna de gênero."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JHo90f1AGN26",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f80f0c1-08f3-431b-8ff9-ddd7a7b0983f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----+---------+\n",
            "|Gênero|count|Proporção|\n",
            "+------+-----+---------+\n",
            "|     F|    5|     50.0|\n",
            "|     M|    5|     50.0|\n",
            "+------+-----+---------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import when\n",
        "\n",
        "\n",
        "# Criar a coluna 'Gênero' com valores  'M' e 'F'\n",
        "df = df.withColumn('Gênero', when(df.ID % 2 == 0, 'F').otherwise('M'))\n",
        "\n",
        "# Calcular a proporção de gêneros\n",
        "proporcao_genero = df.groupBy('Gênero').count()\n",
        "total = df.count()\n",
        "proporcao_genero = proporcao_genero.withColumn('Proporção', (proporcao_genero['count'] / total) * 100)\n",
        "\n",
        "# Exibir a proporção de gêneros\n",
        "proporcao_genero.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qj0ySXwHGOsu"
      },
      "source": [
        "### 15. Correção de Formato de Data: Uniformizar o formato das datas de contratação."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ufzUZBo2GSkV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d052d0dc-bea1-40b9-f4c2-814628754c68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+--------------+-----+------------+-------+-------------------+-----------------+---------------+------+\n",
            "|  ID|          Nome|Idade|        Área|Salario|Data de Contratação|Status de Emprego|Ano_Contratacao|Gênero|\n",
            "+----+--------------+-----+------------+-------+-------------------+-----------------+---------------+------+\n",
            "| 8.0| Luciana Costa| 30.0|  FINANCEIRO| 5200.0|         01/01/2019|            ATIVO|           2019|     F|\n",
            "|10.0| Fernanda Dias| 29.0|          RH| 4800.0|               NULL|            ATIVO|   Desconhecido|     F|\n",
            "| 5.0|  Fabio Santos| 31.0|DESCONHECIDA| 5500.0|         20/11/2017|            ATIVO|           2017|     M|\n",
            "| 2.0|   Maria Souza| 30.0|          RH| 4800.0|         15/03/2019|            ATIVO|           2019|     F|\n",
            "| 7.0|    José Alves| 34.0|   MARKETING| 5400.0|         01/02/2018|          INATIVO|           2018|     M|\n",
            "| 4.0|     Ana Clara| 27.0|   MARKETING| 4800.0|         12/06/2018|            ATIVO|           2018|     F|\n",
            "| 1.0|    João Silva| 29.0|  FINANCEIRO| 5500.0|         01/02/2020|            ATIVO|           2020|     M|\n",
            "| 3.0|Carlos Pereira| 30.0|  FINANCEIRO| 6200.0|         01/04/2020|            ATIVO|           2020|     M|\n",
            "| 6.0|   Sandra Lima| 28.0|          RH| 4800.0|         05/05/2020|            ATIVO|           2020|     F|\n",
            "| 9.0| Paulo Ricardo| 30.0|  FINANCEIRO| 6100.0|         12/12/2020|          INATIVO|           2020|     M|\n",
            "+----+--------------+-----+------------+-------+-------------------+-----------------+---------------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import udf, col, to_date, datediff, current_date, when, date_format, lit\n",
        "from pyspark.sql.types import StringType\n",
        "from datetime import datetime\n",
        "\n",
        "# Função para padronizar datas\n",
        "def padronizar_data(data):\n",
        "    formatos = ['%d/%m/%Y', '%d-%m-%Y', '%Y/%m/%d', '%d.%m.%Y']\n",
        "    for formato in formatos:\n",
        "        try:\n",
        "            return datetime.strptime(data, formato).strftime('%d/%m/%Y')\n",
        "        except:\n",
        "            continue\n",
        "    return None\n",
        "\n",
        "# Registrar a função UDF\n",
        "padronizar_data_udf = udf(padronizar_data, StringType())\n",
        "\n",
        "# Aplicar a função ao DataFrame\n",
        "df = df.withColumn('Data de Contratação', padronizar_data_udf(col('Data de Contratação')))\n",
        "\n",
        "df.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylMz8ESaGTI9"
      },
      "source": [
        "### 16. Impacto de Status no Salário: Comparar salários médios entre funcionários ativos e não ativos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "whScbE--GXGL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "675903a3-c211-47ef-fbe5-395579bbc935"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+-------------+\n",
            "|Status de Emprego|Média_Salário|\n",
            "+-----------------+-------------+\n",
            "|          INATIVO|       5750.0|\n",
            "|            ATIVO|       5200.0|\n",
            "+-----------------+-------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import functions as F # boa prática para importar funções do PySpark\n",
        "# Dividir entre ATIVO e INATIVO na coluna 'Status de Emprego' e calcular a média de salário para cada grupo\n",
        "df_status_salario = df.groupBy('Status de Emprego') \\\n",
        "    .agg(F.mean('Salario').alias('Média_Salário'))\n",
        "\n",
        "df_status_salario.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emzegvlmGXss"
      },
      "source": [
        "### 17. Data de Contratação e Demografia: Relacionar a data de contratação com a idade dos funcionários na época da contratação."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NA92gVQ8GcRa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f68f4b87-e14b-4f14-fa28-3d94d3dbf69d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+-----+-------------------+-----------------+\n",
            "|          Nome|Idade|Data de Contratação|Idade_Contratacao|\n",
            "+--------------+-----+-------------------+-----------------+\n",
            "| Luciana Costa| 30.0|         01/01/2019|             25.0|\n",
            "| Fernanda Dias| 29.0|               NULL|             NULL|\n",
            "|  Fabio Santos| 31.0|         20/11/2017|             25.0|\n",
            "|   Maria Souza| 30.0|         15/03/2019|             25.0|\n",
            "|    José Alves| 34.0|         01/02/2018|             28.0|\n",
            "|     Ana Clara| 27.0|         12/06/2018|             21.0|\n",
            "|    João Silva| 29.0|         01/02/2020|             25.0|\n",
            "|Carlos Pereira| 30.0|         01/04/2020|             26.0|\n",
            "|   Sandra Lima| 28.0|         05/05/2020|             24.0|\n",
            "| Paulo Ricardo| 30.0|         12/12/2020|             27.0|\n",
            "+--------------+-----+-------------------+-----------------+\n",
            "\n",
            "Correlação entre Idade e Idade_Contratacao: 0.335971657404758\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import functions as F\n",
        "\n",
        "# Calcular a idade dos funcionários na data de contratação\n",
        "df_idade_contratacao = df.withColumn(\n",
        "    'Idade_Contratacao',\n",
        "    F.floor(F.datediff(F.current_date(), F.to_date('Data de Contratação', 'dd/MM/yyyy')) / 365.25)\n",
        ")\n",
        "\n",
        "df_idade_contratacao = df_idade_contratacao.withColumn(\n",
        "    'Idade_Contratacao',\n",
        "    F.col('Idade') - F.col('Idade_Contratacao')\n",
        ")\n",
        "\n",
        "# Exibir o DataFrame com a idade na contratação\n",
        "df_idade_contratacao.select('Nome', 'Idade', 'Data de Contratação', 'Idade_Contratacao').show()\n",
        "\n",
        "# calcular correlação entre Idade e Idade_Contratacao\n",
        "correlacao = df_idade_contratacao.stat.corr('Idade', 'Idade_Contratacao')\n",
        "print(f'Correlação entre Idade e Idade_Contratacao: {correlacao}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v30ZHvC0GcjH"
      },
      "source": [
        "### 18. Distribuição de Status de Emprego: Analisar a distribuição do status de emprego (ativo vs. não ativo)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BO0DLtSnGikE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf6a111e-ad84-4fa1-d3f1-6542f575f603"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+--------+\n",
            "|Status de Emprego|Contagem|\n",
            "+-----------------+--------+\n",
            "|          INATIVO|       2|\n",
            "|            ATIVO|       8|\n",
            "+-----------------+--------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import functions as F\n",
        "\n",
        "# Calcular a distribuição do status de emprego (ativo vs. não ativo)\n",
        "df_distribuicao_status = df.groupBy('Status de Emprego') \\\n",
        "    .agg(F.count('Status de Emprego').alias('Contagem'))\n",
        "\n",
        "# Exibir a distribuição do status de emprego\n",
        "df_distribuicao_status.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ogD1IBxGj2r"
      },
      "source": [
        "### 19. Criação de Coluna de Idade de Contratação: Criar uma coluna que calcule a idade do funcionário na época da contratação e analisar os dados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CFeONyqlGnMe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9905f23c-52e2-471e-c041-9cdd9fa69822"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+-----+-------------------+-----------------+\n",
            "|          Nome|Idade|Data de Contratação|Idade_Contratacao|\n",
            "+--------------+-----+-------------------+-----------------+\n",
            "| Luciana Costa| 30.0|         01/01/2019|             24.0|\n",
            "| Fernanda Dias| 29.0|               NULL|             NULL|\n",
            "|  Fabio Santos| 31.0|         20/11/2017|             24.0|\n",
            "|   Maria Souza| 30.0|         15/03/2019|             25.0|\n",
            "|    José Alves| 34.0|         01/02/2018|             27.0|\n",
            "|     Ana Clara| 27.0|         12/06/2018|             21.0|\n",
            "|    João Silva| 29.0|         01/02/2020|             24.0|\n",
            "|Carlos Pereira| 30.0|         01/04/2020|             26.0|\n",
            "|   Sandra Lima| 28.0|         05/05/2020|             24.0|\n",
            "| Paulo Ricardo| 30.0|         12/12/2020|             26.0|\n",
            "+--------------+-----+-------------------+-----------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql.functions import round\n",
        "\n",
        "# Criar uma nova coluna que calcula a idade do funcionário na época da contratação\n",
        "df_idade_contratacao = df.withColumn(\n",
        "    'Idade_Contratacao',\n",
        "    F.col('Idade') - (F.datediff(F.current_date(), F.to_date('Data de Contratação', 'dd/MM/yyyy')) / 365.25)\n",
        ")\n",
        "\n",
        "# Arredondar a coluna 'Idade_Contratacao'\n",
        "df_idade_contratacao = df_idade_contratacao.withColumn(\"Idade_Contratacao\", round(df_idade_contratacao[\"Idade_Contratacao\"], 0))\n",
        "\n",
        "# Exibir o DataFrame com a nova coluna 'Idade_Contratacao'\n",
        "df_idade_contratacao.select('Nome', 'Idade', 'Data de Contratação', 'Idade_Contratacao').show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JW-0G95pGqVU"
      },
      "source": [
        "### 20. Análise de Promoções: Analisar possíveis promoções dentro da empresa ao comparar datas de contratação e aumentos salariais, se houvesse uma coluna histórica de salários.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k8hWaIpsGrnc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9184b3f-65a4-480a-d8a5-c5653591e234"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+-------------------+-------+----------------+\n",
            "|          Nome|Data de Contratação|Salario|Contagem_Salario|\n",
            "+--------------+-------------------+-------+----------------+\n",
            "|   Maria Souza|         15/03/2019| 4800.0|               1|\n",
            "|    João Silva|         01/02/2020| 5500.0|               1|\n",
            "|  Fabio Santos|         20/11/2017| 5500.0|               1|\n",
            "|     Ana Clara|         12/06/2018| 4800.0|               1|\n",
            "| Luciana Costa|         01/01/2019| 5200.0|               1|\n",
            "| Paulo Ricardo|         12/12/2020| 6100.0|               1|\n",
            "|    José Alves|         01/02/2018| 5400.0|               1|\n",
            "| Fernanda Dias|               NULL| 4800.0|               1|\n",
            "|Carlos Pereira|         01/04/2020| 6200.0|               1|\n",
            "|   Sandra Lima|         05/05/2020| 4800.0|               1|\n",
            "+--------------+-------------------+-------+----------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 20. Análise de Promoções: Analisar possíveis promoções dentro da empresa ao comparar datas de contratação e aumentos salariais, se houvesse uma coluna histórica de salários\n",
        "from pyspark.sql import functions as F\n",
        "\n",
        "# agrupar por 'Nome', 'Data de Contratação' e 'Salario'\n",
        "df_promocoes = df.groupBy('Nome', 'Data de Contratação', 'Salario') \\\n",
        "    .agg(F.count('Salario').alias('Contagem_Salario'))\n",
        "\n",
        "# Exibir o DataFrame\n",
        "df_promocoes.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IAczNjgPGvo_"
      },
      "source": [
        "### 21. Análise de Desempenho Temporal: Verificar se o tempo de casa influencia o salário ou a permanência no emprego."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G04Sp5trG0tT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4373b406-e802-4403-85a0-62b1721fdf20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correlação entre Tempo de Casa e Salário: 0.08752227235896064\n",
            "+-----------------+-------------------+-------------+\n",
            "|Status de Emprego|Média_Tempo_de_Casa|Média_Salario|\n",
            "+-----------------+-------------------+-------------+\n",
            "|          INATIVO|               5.15|       5750.0|\n",
            "|            ATIVO|  5.355714285714285|       5200.0|\n",
            "+-----------------+-------------------+-------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import functions as F\n",
        "\n",
        "# Adicionar coluna de Tempo de Casa (em anos)\n",
        "df = df.withColumn(\n",
        "    \"Tempo_de_Casa\",\n",
        "    F.round(F.datediff(F.current_date(), F.to_date(\"Data de Contratação\", \"dd/MM/yyyy\")) / 365.25, 2)\n",
        ")\n",
        "# Calcular correlação entre Tempo de Casa e Salário\n",
        "correlacao = df.stat.corr(\"Tempo_de_Casa\", \"Salario\")\n",
        "print(f\"Correlação entre Tempo de Casa e Salário: {correlacao}\")\n",
        "\n",
        "# Agrupar por Status de Emprego e calcular média de Tempo de Casa\n",
        "df_grouped = df.groupBy(\"Status de Emprego\").agg(\n",
        "    F.avg(\"Tempo_de_Casa\").alias(\"Média_Tempo_de_Casa\"),\n",
        "    F.avg(\"Salario\").alias(\"Média_Salario\")\n",
        ")\n",
        "\n",
        "# Mostrar os resultados\n",
        "df_grouped.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08L8CwMGG1Qd"
      },
      "source": [
        "### 22. Filtragem por Data de Contratação: Identificar funcionários contratados em períodos específicos (e.g., antes de 2019, entre 2019-2020)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "70ByMBeKG5EJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5489769a-8e9b-4158-c4b8-521de2ffedb6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Funcionários contratados antes de 2019:\n",
            "+---+------------+-----+------------+-------+-------------------+-----------------+---------------+------+-------------+\n",
            "| ID|        Nome|Idade|        Área|Salario|Data de Contratação|Status de Emprego|Ano_Contratacao|Gênero|Tempo_de_Casa|\n",
            "+---+------------+-----+------------+-------+-------------------+-----------------+---------------+------+-------------+\n",
            "|5.0|Fabio Santos| 31.0|DESCONHECIDA| 5500.0|         20/11/2017|            ATIVO|           2017|     M|         6.78|\n",
            "|7.0|  José Alves| 34.0|   MARKETING| 5400.0|         01/02/2018|          INATIVO|           2018|     M|         6.58|\n",
            "|4.0|   Ana Clara| 27.0|   MARKETING| 4800.0|         12/06/2018|            ATIVO|           2018|     F|         6.23|\n",
            "+---+------------+-----+------------+-------+-------------------+-----------------+---------------+------+-------------+\n",
            "\n",
            "\n",
            "Funcionários contratados entre 2019 e 2020:\n",
            "+---+--------------+-----+----------+-------+-------------------+-----------------+---------------+------+-------------+\n",
            "| ID|          Nome|Idade|      Área|Salario|Data de Contratação|Status de Emprego|Ano_Contratacao|Gênero|Tempo_de_Casa|\n",
            "+---+--------------+-----+----------+-------+-------------------+-----------------+---------------+------+-------------+\n",
            "|8.0| Luciana Costa| 30.0|FINANCEIRO| 5200.0|         01/01/2019|            ATIVO|           2019|     F|         5.67|\n",
            "|2.0|   Maria Souza| 30.0|        RH| 4800.0|         15/03/2019|            ATIVO|           2019|     F|         5.47|\n",
            "|1.0|    João Silva| 29.0|FINANCEIRO| 5500.0|         01/02/2020|            ATIVO|           2020|     M|         4.59|\n",
            "|3.0|Carlos Pereira| 30.0|FINANCEIRO| 6200.0|         01/04/2020|            ATIVO|           2020|     M|         4.42|\n",
            "|6.0|   Sandra Lima| 28.0|        RH| 4800.0|         05/05/2020|            ATIVO|           2020|     F|         4.33|\n",
            "|9.0| Paulo Ricardo| 30.0|FINANCEIRO| 6100.0|         12/12/2020|          INATIVO|           2020|     M|         3.72|\n",
            "+---+--------------+-----+----------+-------+-------------------+-----------------+---------------+------+-------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import functions as F\n",
        "\n",
        "# Filtrar funcionários contratados antes de 2019\n",
        "df_antes_2019 = df.filter(F.year(F.to_date('Data de Contratação', 'dd/MM/yyyy')) < 2019)\n",
        "\n",
        "# Filtrar funcionários contratados entre 2019 e 2020\n",
        "df_entre_2019_2020 = df.filter((F.year(F.to_date('Data de Contratação', 'dd/MM/yyyy')) >= 2019) &\n",
        "                               (F.year(F.to_date('Data de Contratação', 'dd/MM/yyyy')) <= 2020))\n",
        "\n",
        "# Exibir os DataFrames\n",
        "print('Funcionários contratados antes de 2019:')\n",
        "df_antes_2019.show()\n",
        "\n",
        "print()\n",
        "\n",
        "print('Funcionários contratados entre 2019 e 2020:')\n",
        "df_entre_2019_2020.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTAirpXGG5Zs"
      },
      "source": [
        "### 23. Análise de Status de Emprego e Tempo de Casa: Verificar a relação entre tempo de casa e status de emprego (ativo vs. não ativo)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w4RoeJSQG-Nb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7d85dee-1e57-41e9-e113-5adc377d6ed4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+-------------------+\n",
            "|Status de Emprego|Média_Tempo_de_Casa|\n",
            "+-----------------+-------------------+\n",
            "|          INATIVO|               5.15|\n",
            "|            ATIVO|               5.36|\n",
            "+-----------------+-------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import functions as F\n",
        "\n",
        "# Calcular o Tempo de Casa em anos e arredondar para 2 casas decimais\n",
        "df = df.withColumn(\n",
        "    'Tempo_de_Casa',\n",
        "    F.round(F.datediff(F.current_date(), F.to_date('Data de Contratação', 'dd/MM/yyyy')) / 365.25, 2)\n",
        ")\n",
        "\n",
        "# Calcular a média de Tempo de Casa por Status de Emprego e arredondar a média para 2 casas decimais\n",
        "df_tempo_casa_status = df.groupBy('Status de Emprego') \\\n",
        "    .agg(F.round(F.mean('Tempo_de_Casa'), 2).alias('Média_Tempo_de_Casa'))\n",
        "\n",
        "# Exibir o DataFrame\n",
        "df_tempo_casa_status.show()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2yaJUjQG-8a"
      },
      "source": [
        "### 24. Identificação de Funcionários Veteranos: Encontrar os funcionários com maior tempo de casa e analisar seu impacto na empresa."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RIzEdG2jHDiZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab1260d1-50c4-41ac-e1f3-9f7eb79d9d86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-------------+-----+------------+-------+-------------------+-----------------+---------------+------+-------------+\n",
            "| ID|         Nome|Idade|        Área|Salario|Data de Contratação|Status de Emprego|Ano_Contratacao|Gênero|Tempo_de_Casa|\n",
            "+---+-------------+-----+------------+-------+-------------------+-----------------+---------------+------+-------------+\n",
            "|8.0|Luciana Costa| 30.0|  FINANCEIRO| 5200.0|         01/01/2019|            ATIVO|           2019|     F|         5.67|\n",
            "|5.0| Fabio Santos| 31.0|DESCONHECIDA| 5500.0|         20/11/2017|            ATIVO|           2017|     M|         6.78|\n",
            "|2.0|  Maria Souza| 30.0|          RH| 4800.0|         15/03/2019|            ATIVO|           2019|     F|         5.47|\n",
            "|7.0|   José Alves| 34.0|   MARKETING| 5400.0|         01/02/2018|          INATIVO|           2018|     M|         6.58|\n",
            "|4.0|    Ana Clara| 27.0|   MARKETING| 4800.0|         12/06/2018|            ATIVO|           2018|     F|         6.23|\n",
            "+---+-------------+-----+------------+-------+-------------------+-----------------+---------------+------+-------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from pyspark.sql import functions as F\n",
        "\n",
        "# Calcular o Tempo de Casa de funcionários com mais de 5 anos\n",
        "df_veteranos = df.withColumn(\n",
        "    'Tempo_de_Casa',\n",
        "    F.round(F.datediff(F.current_date(), F.to_date('Data de Contratação', 'dd/MM/yyyy')) / 365.25, 2)\n",
        ").filter(F.col('Tempo_de_Casa') > 5)\n",
        "\n",
        "# Exibir os funcionários veteranos\n",
        "df_veteranos.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGBHJXTfHD6B"
      },
      "source": [
        "### 25. Análise de Tendências de Contratação: Identificar padrões de contratação ao longo do tempo, como sazonalidade."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CA9WRqT5HHEB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcdb105a-763d-4c82-fafb-72a78dc4ef2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+----+----------------------+\n",
            "| Ano| Mês|Número_de_Contratações|\n",
            "+----+----+----------------------+\n",
            "|NULL|NULL|                     1|\n",
            "|2017|  11|                     1|\n",
            "|2018|   2|                     1|\n",
            "|2018|   6|                     1|\n",
            "|2019|   1|                     1|\n",
            "|2019|   3|                     1|\n",
            "|2020|   2|                     1|\n",
            "|2020|   4|                     1|\n",
            "|2020|   5|                     1|\n",
            "|2020|  12|                     1|\n",
            "+----+----+----------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import functions as F\n",
        "\n",
        "# Agrupar por ano e mês da data de contratação e contar o número de contratações\n",
        "df_tendencias = df.groupBy(\n",
        "    F.year(F.to_date('Data de Contratação', 'dd/MM/yyyy')).alias('Ano'),\n",
        "    F.month(F.to_date('Data de Contratação', 'dd/MM/yyyy')).alias('Mês')\n",
        ").agg(\n",
        "    F.count('*').alias('Número_de_Contratações')\n",
        ").orderBy('Ano', 'Mês')\n",
        "\n",
        "# Exibir os resultados\n",
        "df_tendencias.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4o_s0AKlHHWv"
      },
      "source": [
        "### 26. Salário Máximo e Mínimo por Departamento: Determinar os salários mais altos e mais baixos dentro de cada departamento.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eph5hrhYHKnP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d44c6392-4431-4501-e837-5fa12514e1ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+--------------+--------------+\n",
            "|        Área|Salario_Mínimo|Salario_Máximo|\n",
            "+------------+--------------+--------------+\n",
            "|   MARKETING|        4800.0|        5400.0|\n",
            "|          RH|        4800.0|        4800.0|\n",
            "|DESCONHECIDA|        5500.0|        5500.0|\n",
            "|  FINANCEIRO|        5200.0|        6200.0|\n",
            "+------------+--------------+--------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql.functions import max, min\n",
        "# Calcular o salário minimum e máximo por departamento\n",
        "df_salario_min_max = df.groupBy('Área') \\\n",
        "    .agg(\n",
        "        F.min('Salario').alias('Salario_Mínimo'),\n",
        "        F.max('Salario').alias('Salario_Máximo')\n",
        "\n",
        "    )\n",
        "\n",
        "# Exibir os salários minimum e máximo por departamento\n",
        "df_salario_min_max.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cohtfXq3HLB9"
      },
      "source": [
        "### 27. Classificação de Funcionários por Salário: Criar rankings de funcionários por salário dentro de cada departamento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nyR5dca7HOTO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "271088c3-daac-489b-db73-1306baa52842"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+------------+-------+----+\n",
            "|          Nome|        Área|Salario|Rank|\n",
            "+--------------+------------+-------+----+\n",
            "|  Fabio Santos|DESCONHECIDA| 5500.0|   1|\n",
            "|Carlos Pereira|  FINANCEIRO| 6200.0|   1|\n",
            "| Paulo Ricardo|  FINANCEIRO| 6100.0|   2|\n",
            "|    João Silva|  FINANCEIRO| 5500.0|   3|\n",
            "| Luciana Costa|  FINANCEIRO| 5200.0|   4|\n",
            "|    José Alves|   MARKETING| 5400.0|   1|\n",
            "|     Ana Clara|   MARKETING| 4800.0|   2|\n",
            "| Fernanda Dias|          RH| 4800.0|   1|\n",
            "|   Maria Souza|          RH| 4800.0|   1|\n",
            "|   Sandra Lima|          RH| 4800.0|   1|\n",
            "+--------------+------------+-------+----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql.window import Window\n",
        "\n",
        "# Definir a janela para classificação por departamento e ordenar por salário em ordem decrescente\n",
        "window_spec = Window.partitionBy('Área').orderBy(F.desc('Salario'))\n",
        "\n",
        "# Adicionar uma coluna de ranking baseado no salário dentro de cada departamento\n",
        "df_ranked = df.withColumn('Rank', F.rank().over(window_spec))\n",
        "\n",
        "# Exibir o DataFrame com os rankings\n",
        "df_ranked.select('Nome', 'Área', 'Salario', 'Rank').show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0ov35v_HPms"
      },
      "source": [
        "### 28. Projeção de Aposentadoria: Estimar o número de funcionários que podem se aposentar em breve com base na idade."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5-165aOwHUUF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cb0f044-ae98-48c1-912f-c54318727b68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número de funcionários elegíveis para aposentadoria: 0\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import functions as F\n",
        "\n",
        "# Definir a idade de aposentadoria\n",
        "idade_aposentadoria = 65\n",
        "\n",
        "# Filtrar e contar os funcionários elegíveis para aposentadoria\n",
        "num_aposentadoria = df.filter(F.col('Idade') >= idade_aposentadoria).count()\n",
        "\n",
        "# Exibir o número de funcionários elegíveis para aposentadoria\n",
        "print(f'Número de funcionários elegíveis para aposentadoria: {num_aposentadoria}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1lnKTu5HUoe"
      },
      "source": [
        "### 29. Segmentação de Funcionários por Faixa Salarial: Agrupar funcionários em faixas salariais (e.g., 2000-3000, 3001-4000) e analisar a distribuição."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JRW9XuZiHXsZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75b1c42c-66fd-4b37-b573-a0e9b969f4ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+-----+\n",
            "|Faixa_Salarial|count|\n",
            "+--------------+-----+\n",
            "|     4001-5000|    4|\n",
            "|     5001-6000|    4|\n",
            "|     6001-7000|    2|\n",
            "+--------------+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import functions as F\n",
        "\n",
        "# Definir as faixas salariais e usar `when` para criar a expressão SQL\n",
        "faixas_salarial_expr = F.when((F.col('Salario') >= 2000) & (F.col('Salario') <= 3000), '2000-3000') \\\n",
        "    .when((F.col('Salario') >= 3001) & (F.col('Salario') <= 4000), '3001-4000') \\\n",
        "    .when((F.col('Salario') >= 4001) & (F.col('Salario') <= 5000), '4001-5000') \\\n",
        "    .when((F.col('Salario') >= 5001) & (F.col('Salario') <= 6000), '5001-6000') \\\n",
        "    .when((F.col('Salario') >= 6001) & (F.col('Salario') <= 7000), '6001-7000') \\\n",
        "    .otherwise('Outros')\n",
        "\n",
        "# Contar a distribuição de funcionários por faixa salarial\n",
        "df_distribuicao_faixa = df.groupBy(faixas_salarial_expr.alias('Faixa_Salarial')) \\\n",
        "    .count() \\\n",
        "    .orderBy('Faixa_Salarial')\n",
        "\n",
        "# Exibir o resultado\n",
        "df_distribuicao_faixa.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xP7PSlhwHZwp"
      },
      "source": [
        "### 30. Análise de Equidade Salarial: Verificar se há desigualdade salarial dentro de departamentos específicos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FDjfGnB8Hc6j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c73f5af-a522-433e-988a-9b1e0f7054d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+------------+-------------+\n",
            "|Gênero|        Área|Média_Salário|\n",
            "+------+------------+-------------+\n",
            "|     F|  FINANCEIRO|       5200.0|\n",
            "|     F|   MARKETING|       4800.0|\n",
            "|     F|          RH|       4800.0|\n",
            "|     M|DESCONHECIDA|       5500.0|\n",
            "|     M|  FINANCEIRO|       5933.3|\n",
            "|     M|   MARKETING|       5400.0|\n",
            "+------+------------+-------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import functions as F\n",
        "\n",
        "# Calcular a média de salário por 'Gênero' e 'Área'\n",
        "df_genero_area = df.groupBy('Gênero', 'Área') \\\n",
        "    .agg(F.round(F.mean('Salario'), 1).alias('Média_Salário')) \\\n",
        "    .orderBy('Gênero', 'Área')\n",
        "\n",
        "# Exibir o DataFrame com a média de salário por gênero e área\n",
        "df_genero_area.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_RftG80HlY0"
      },
      "source": [
        "### 31. Comparação de Salários por Período de Contratação: Comparar os salários de funcionários contratados em diferentes anos para identificar tendências de aumento salarial."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LTfwx1LrHm9r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f3c700d-fad9-4836-e2ca-a03200a6faeb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+-------------+\n",
            "|Ano_Contratacao|Media_Salario|\n",
            "+---------------+-------------+\n",
            "|           NULL|       4800.0|\n",
            "|           2017|       5500.0|\n",
            "|           2018|       5100.0|\n",
            "|           2019|       5000.0|\n",
            "|           2020|       5650.0|\n",
            "+---------------+-------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from pyspark.sql import functions as F\n",
        "\n",
        "# Extrair o ano da data de contratação\n",
        "df = df.withColumn('Ano_Contratacao', F.year(F.to_date('Data de Contratação', 'dd/MM/yyyy')))\n",
        "\n",
        "# Calcular a média de salário por ano de contratação\n",
        "df_salario_ano = df.groupBy('Ano_Contratacao').agg(F.mean('Salario').alias('Media_Salario')).sort('Ano_Contratacao')\n",
        "df_salario_ano.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdkZMJ14HnUt"
      },
      "source": [
        "### 32. Criação de Coluna de Faixa Etária: Agrupar os funcionários em faixas etárias (e.g., 20-30 anos, 31-40 anos) e analisar diferenças entre elas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DhVXJZuwHsW_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd7f8004-0921-438c-af62-d2f4751ba6ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+--------------+-----+------------+-------+-------------------+-----------------+---------------+------+-------------+------------+\n",
            "|  ID|          Nome|Idade|        Área|Salario|Data de Contratação|Status de Emprego|Ano_Contratacao|Gênero|Tempo_de_Casa|Faixa_Etaria|\n",
            "+----+--------------+-----+------------+-------+-------------------+-----------------+---------------+------+-------------+------------+\n",
            "| 8.0| Luciana Costa| 30.0|  FINANCEIRO| 5200.0|         01/01/2019|            ATIVO|           2019|     F|         5.67|  20-30 anos|\n",
            "|10.0| Fernanda Dias| 29.0|          RH| 4800.0|               NULL|            ATIVO|           NULL|     F|         NULL|  20-30 anos|\n",
            "| 5.0|  Fabio Santos| 31.0|DESCONHECIDA| 5500.0|         20/11/2017|            ATIVO|           2017|     M|         6.78|  31-40 anos|\n",
            "| 2.0|   Maria Souza| 30.0|          RH| 4800.0|         15/03/2019|            ATIVO|           2019|     F|         5.47|  20-30 anos|\n",
            "| 7.0|    José Alves| 34.0|   MARKETING| 5400.0|         01/02/2018|          INATIVO|           2018|     M|         6.58|  31-40 anos|\n",
            "| 4.0|     Ana Clara| 27.0|   MARKETING| 4800.0|         12/06/2018|            ATIVO|           2018|     F|         6.23|  20-30 anos|\n",
            "| 1.0|    João Silva| 29.0|  FINANCEIRO| 5500.0|         01/02/2020|            ATIVO|           2020|     M|         4.59|  20-30 anos|\n",
            "| 3.0|Carlos Pereira| 30.0|  FINANCEIRO| 6200.0|         01/04/2020|            ATIVO|           2020|     M|         4.42|  20-30 anos|\n",
            "| 6.0|   Sandra Lima| 28.0|          RH| 4800.0|         05/05/2020|            ATIVO|           2020|     F|         4.33|  20-30 anos|\n",
            "| 9.0| Paulo Ricardo| 30.0|  FINANCEIRO| 6100.0|         12/12/2020|          INATIVO|           2020|     M|         3.72|  20-30 anos|\n",
            "+----+--------------+-----+------------+-------+-------------------+-----------------+---------------+------+-------------+------------+\n",
            "\n",
            "+------------+-----+\n",
            "|Faixa_Etaria|count|\n",
            "+------------+-----+\n",
            "|  20-30 anos|    8|\n",
            "|  31-40 anos|    2|\n",
            "+------------+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import functions as F\n",
        "\n",
        "# Definir a expressão para a faixa etária\n",
        "faixa_etaria_expr = F.when((F.col('Idade') >= 20) & (F.col('Idade') <= 30), '20-30 anos') \\\n",
        "    .when((F.col('Idade') >= 31) & (F.col('Idade') <= 40), '31-40 anos') \\\n",
        "    .when((F.col('Idade') >= 41) & (F.col('Idade') <= 50), '41-50 anos') \\\n",
        "    .when((F.col('Idade') >= 51) & (F.col('Idade') <= 60), '51-60 anos') \\\n",
        "    .otherwise('Outras')\n",
        "\n",
        "# Adicionar a coluna de faixa etária ao DataFrame\n",
        "df_faixa_etaria = df.withColumn('Faixa_Etaria', faixa_etaria_expr)\n",
        "\n",
        "# Exibir o DataFrame com a nova coluna\n",
        "df_faixa_etaria.show()\n",
        "\n",
        "# Contar a distribuição de funcionários por faixa etária\n",
        "df_distribuicao_faixa_etaria = df_faixa_etaria.groupBy('Faixa_Etaria') \\\n",
        "    .count() \\\n",
        "    .orderBy('Faixa_Etaria')\n",
        "\n",
        "# Exibir o resultado da distribuição de faixa etária dos funcionários\n",
        "df_distribuicao_faixa_etaria.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQu7ukA_Hsq1"
      },
      "source": [
        "### 33. Relação Entre Área e Tempo de Contratação: Identificar se alguns departamentos tendem a manter seus funcionários por mais tempo do que outros.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ynw0GUDsHwyG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3013bd59-87ac-465d-ce6a-a71b51c2c2d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+-------------------+\n",
            "|        Área|Média_Tempo_de_Casa|\n",
            "+------------+-------------------+\n",
            "|  FINANCEIRO|                4.6|\n",
            "|          RH|                4.9|\n",
            "|   MARKETING|              6.405|\n",
            "|DESCONHECIDA|               6.78|\n",
            "+------------+-------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from pyspark.sql import functions as F\n",
        "# Calcular a média do Tempo de Casa por Área\n",
        "df_tempo_area = df.groupBy('Área') \\\n",
        "    .agg(F.mean('Tempo_de_Casa').alias('Média_Tempo_de_Casa')) \\\n",
        "    .orderBy('Média_Tempo_de_Casa')\n",
        "\n",
        "# Exibir o DataFrame com a média de Tempo de Casa por Área\n",
        "df_tempo_area.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6R_KRafxHxDI"
      },
      "source": [
        "### 34. Previsão de Turnover: Usar dados históricos para prever quais funcionários têm maior probabilidade de deixar a empresa."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Identificar funcionários com maior probabilidade de deixar a empresa (probabilidade de 'INATIVO' > 0.5)\n",
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import DoubleType\n",
        "from pyspark.ml.feature import Imputer, VectorAssembler\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "\n",
        "# Converter a coluna 'Status de Emprego' para numérica: 1 para 'ATIVO' e 0 para 'INATIVO'\n",
        "df = df.withColumn('Status_Emprego_Num', when(df['Status de Emprego'] == 'ATIVO', 1).otherwise(0))\n",
        "\n",
        "# Selecionar as colunas relevantes para o modelo, incluindo 'Nome'\n",
        "df_modelo = df.select('Nome', 'Idade', 'Salario', 'Tempo_de_Casa', 'Status_Emprego_Num')  # Include 'Nome' here\n",
        "\n",
        "# Preencher valores nulos com a média da coluna (ou outra estratégia de imputação)\n",
        "imputer = Imputer(inputCols=['Idade', 'Salario', 'Tempo_de_Casa'],\n",
        "                  outputCols=['Idade_Imputed', 'Salario_Imputed', 'Tempo_de_Casa_Imputed'])\n",
        "df_modelo = imputer.fit(df_modelo).transform(df_modelo)\n",
        "\n",
        "# Criar um VectorAssembler para combinar as features em uma única coluna\n",
        "assembler = VectorAssembler(inputCols=['Idade_Imputed', 'Salario_Imputed', 'Tempo_de_Casa_Imputed'],\n",
        "                            outputCol='features') # Use as colunas imputadas\n",
        "df_modelo = assembler.transform(df_modelo)\n",
        "\n",
        "# Dividir os dados em conjuntos de treinamento e teste\n",
        "train_data, test_data = df_modelo.randomSplit([0.7, 0.3], seed=42)\n",
        "\n",
        "# Importar e treinar um modelo de Machine Learning (ex: Regressão Logística)\n",
        "lr = LogisticRegression(featuresCol='features', labelCol='Status_Emprego_Num')\n",
        "model = lr.fit(train_data)\n",
        "\n",
        "# Fazer previsões no conjunto de teste\n",
        "predictions = model.transform(test_data)\n",
        "\n",
        "# Avaliar o modelo\n",
        "evaluator = BinaryClassificationEvaluator(labelCol='Status_Emprego_Num')\n",
        "auc = evaluator.evaluate(predictions)\n",
        "print(f'AUC: {auc}')\n",
        "\n",
        "# Define a UDF to extract the probability of 'INATIVO' (index 1)\n",
        "extract_inativo_prob = udf(lambda v: float(v[1]), DoubleType())\n",
        "\n",
        "# Create the 'prob_inativo' column\n",
        "funcionarios_risco = predictions.withColumn('prob_inativo', extract_inativo_prob(predictions['probability']))\n",
        "\n",
        "# Now you can filter using the newly created column\n",
        "funcionarios_risco = funcionarios_risco.filter(funcionarios_risco['prob_inativo'] > 0.5)\n",
        "\n",
        "# Select columns including 'Nome'\n",
        "funcionarios_risco.select('Nome', 'Idade', 'Salario', 'Tempo_de_Casa', 'prediction', 'probability', 'prob_inativo').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xSHXB_fzSZfK",
        "outputId": "44b710bd-b125-4b54-9b69-74d988224141"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC: 0.3333333333333333\n",
            "+-------------+-----+-------+-------------+----------+--------------------+------------------+\n",
            "|         Nome|Idade|Salario|Tempo_de_Casa|prediction|         probability|      prob_inativo|\n",
            "+-------------+-----+-------+-------------+----------+--------------------+------------------+\n",
            "|Luciana Costa| 30.0| 5200.0|         5.67|       1.0|[1.34017873273946...|0.9999865982126726|\n",
            "|Paulo Ricardo| 30.0| 6100.0|         3.72|       1.0|[5.14160248141845...|0.9999999999994859|\n",
            "|  Sandra Lima| 28.0| 4800.0|         4.33|       1.0|[4.11948773526440...|               1.0|\n",
            "+-------------+-----+-------+-------------+----------+--------------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXtTRWvhH0pv"
      },
      "source": [
        "### 35. Análise de Homogeneidade Salarial: Verificar a homogeneidade dos salários dentro de cada departamento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lJ8A6UNxH3vJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca0df596-df57-40b1-c319-1c9635aea14f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+-------------+---------------------+\n",
            "|        Área|Média_Salario|Desvio_Padrao_Salario|\n",
            "+------------+-------------+---------------------+\n",
            "|   MARKETING|       5100.0|                424.3|\n",
            "|          RH|       4800.0|                  0.0|\n",
            "|DESCONHECIDA|       5500.0|                 NULL|\n",
            "|  FINANCEIRO|       5750.0|                479.6|\n",
            "+------------+-------------+---------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from pyspark.sql import functions as F\n",
        "\n",
        "# Calcular a média e desvio padrão dos salários por departamento\n",
        "df_salario_stats = df.groupBy('Área') \\\n",
        "    .agg(\n",
        "        F.mean('Salario').alias('Média_Salario'),\n",
        "        F.round(F.stddev('Salario'), 1).alias('Desvio_Padrao_Salario')\n",
        "    )\n",
        "\n",
        "\n",
        "df_salario_stats.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4kpsnGkrH4GJ"
      },
      "source": [
        "### 36. Detecção de Funcionários Com Anomalias: Identificar funcionários com salários e idades que destoam significativamente dos outros no mesmo departamento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rre5UpfGH65C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63dd0a3d-88f0-4afe-ceb7-c8cf869bcfaa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+-------------+---------------------+-----------+-------------------+\n",
            "|        Área|Média_Salario|Desvio_Padrao_Salario|Média_Idade|Desvio_Padrao_Idade|\n",
            "+------------+-------------+---------------------+-----------+-------------------+\n",
            "|   MARKETING|       5100.0|   424.26406871192853|       30.5|  4.949747468305833|\n",
            "|          RH|       4800.0|                  0.0|       29.0|                1.0|\n",
            "|DESCONHECIDA|       5500.0|                 NULL|       31.0|               NULL|\n",
            "|  FINANCEIRO|       5750.0|   479.58315233127206|      29.75| 0.4999999999999998|\n",
            "+------------+-------------+---------------------+-----------+-------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import functions as F\n",
        "\n",
        "# Calcular a média e desvio padrão dos salários e idades por departamento\n",
        "df_stats = df.groupBy('Área') \\\n",
        "    .agg(\n",
        "        F.mean('Salario').alias('Média_Salario'),\n",
        "        F.stddev('Salario').alias('Desvio_Padrao_Salario'),\n",
        "        F.mean('Idade').alias('Média_Idade'),\n",
        "        F.stddev('Idade').alias('Desvio_Padrao_Idade')\n",
        "    )\n",
        "\n",
        "# Exibir o DataFrame com as estatísticas por departamento\n",
        "df_stats.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHWhD7OFH7Of"
      },
      "source": [
        "### 37. Comparação de Salários por Região: Se houvesse uma coluna de localização, comparar os salários entre diferentes regiões."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "89ywaOz3H9zf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "238400e4-be79-40dc-8870-3d467156b405"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----------------+\n",
            "|Região|    Média_Salário|\n",
            "+------+-----------------+\n",
            "|   Sul|           4800.0|\n",
            "| Norte|           5750.0|\n",
            "|Centro|5233.333333333333|\n",
            "+------+-----------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import functions as F\n",
        "\n",
        "# Adicionar uma coluna fictícia de localização\n",
        "df_com_regiao = df.withColumn('Região', F.when(F.col('Área') == 'FINANCEIRO', 'Norte')\n",
        "                                      .when(F.col('Área') == 'RH', 'Sul')\n",
        "                                      .otherwise('Centro'))\n",
        "\n",
        "# Calcular a média de salário por região\n",
        "df_salario_regiao = df_com_regiao.groupBy('Região') \\\n",
        "    .agg(F.mean('Salario').alias('Média_Salário'))\n",
        "\n",
        "# Exibir o DataFrame com a média de salário por região\n",
        "df_salario_regiao.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6CYQtRhH-KS"
      },
      "source": [
        "### 38. Criação de Métricas Personalizadas: Desenvolver novas métricas como \"salário ajustado pela idade\" ou \"tempo de casa ajustado pela idade\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yNX58rG7IP5d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "390f2e79-6c6b-4559-b9ad-311a5e74e917"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+-------+-----+----------------------+-------------------------+\n",
            "|          Nome|Salario|Idade|Salario_Ajustado_Idade|Tempo_Casa_Ajustado_Idade|\n",
            "+--------------+-------+-----+----------------------+-------------------------+\n",
            "| Luciana Costa| 5200.0| 30.0|    173.33333333333334|                    0.189|\n",
            "| Fernanda Dias| 4800.0| 29.0|    165.51724137931035|                     NULL|\n",
            "|  Fabio Santos| 5500.0| 31.0|    177.41935483870967|      0.21870967741935485|\n",
            "|   Maria Souza| 4800.0| 30.0|                 160.0|      0.18233333333333332|\n",
            "|    José Alves| 5400.0| 34.0|     158.8235294117647|       0.1935294117647059|\n",
            "|     Ana Clara| 4800.0| 27.0|    177.77777777777777|      0.23074074074074075|\n",
            "|    João Silva| 5500.0| 29.0|     189.6551724137931|      0.15827586206896552|\n",
            "|Carlos Pereira| 6200.0| 30.0|    206.66666666666666|      0.14733333333333334|\n",
            "|   Sandra Lima| 4800.0| 28.0|    171.42857142857142|      0.15464285714285714|\n",
            "| Paulo Ricardo| 6100.0| 30.0|    203.33333333333334|      0.12400000000000001|\n",
            "+--------------+-------+-----+----------------------+-------------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 38. Criação de Métricas Personalizadas: Desenvolver novas métricas como \"salário ajustado pela idade\" ou \"tempo de casa ajustado pela idade\".\n",
        "from pyspark.sql import functions as F\n",
        "\n",
        "# Calcular o salário ajustado pela idade\n",
        "df = df.withColumn('Salario_Ajustado_Idade', F.col('Salario') / F.col('Idade'))\n",
        "\n",
        "# Calcular o tempo de casa ajustado pela idade\n",
        "df = df.withColumn('Tempo_Casa_Ajustado_Idade', F.col('Tempo_de_Casa') / F.col('Idade'))\n",
        "\n",
        "# Exibir o DataFrame com as novas métricas\n",
        "df.select('Nome', 'Salario', 'Idade', 'Salario_Ajustado_Idade', 'Tempo_Casa_Ajustado_Idade').show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbehSiJeIQK8"
      },
      "source": [
        "### 39. Análise de Recrutamento Recente: Focar na análise dos funcionários contratados nos últimos 12 meses para ver tendências."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GSG5MiyZIUB9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0744f7a4-a2e7-46d2-e61e-5d2749bb290f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Média salarial dos funcionários contratados nos últimos 12 meses: None\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import functions as F\n",
        "\n",
        "# Filtrar funcionários contratados nos últimos 12 meses\n",
        "df_recrutamento_recente = df.filter(F.datediff(F.current_date(), F.to_date('Data de Contratação', 'dd/MM/yyyy')) <= 365)\n",
        "\n",
        "# Analisar tendências de recrutamento recente (exemplo: média salarial)\n",
        "media_salario_recente = df_recrutamento_recente.agg(F.mean('Salario').alias('Média_Salario_Recente')).collect()[0][0]\n",
        "\n",
        "# Exibir a média salarial dos funcionários contratados recentemente\n",
        "print(f'Média salarial dos funcionários contratados nos últimos 12 meses: {media_salario_recente}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSlsqlK6IUVQ"
      },
      "source": [
        "### 40. Distribuição de Funcionários por Departamento: Quantificar o número de funcionários por departamento e comparar com a média salarial.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XvfwIb1vIXgd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6a23898-9aed-417c-fdda-c5ab3030d21a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+-------------+-------------------+\n",
            "|        Área|Média_Salário|Número_Funcionários|\n",
            "+------------+-------------+-------------------+\n",
            "|   MARKETING|       5100.0|                  2|\n",
            "|          RH|       4800.0|                  3|\n",
            "|DESCONHECIDA|       5500.0|                  1|\n",
            "|  FINANCEIRO|       5750.0|                  4|\n",
            "+------------+-------------+-------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from pyspark.sql import functions as F\n",
        "\n",
        "# Calcular a média de salário por departamento e contar o número de funcionários\n",
        "df_media_salario = df.groupBy('Área') \\\n",
        "    .agg(F.mean('Salario').alias('Média_Salário'),\n",
        "         F.count('Nome').alias('Número_Funcionários'))\n",
        "\n",
        "# Exibir o DataFrame com a média salarial e o número de funcionários por departamento\n",
        "df_media_salario.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycW9lIKAIX6r"
      },
      "source": [
        "### 41. Análise de Rotatividade por Departamento: Verificar se há departamentos com alta rotatividade de funcionários."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WKIwQ14cIa4q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b9bde39-d11f-4d6d-8374-0880542fdeb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+---------------------+-------------+-----------+\n",
            "|        Área|Contagem_Funcionários|Média_Salário|Média_Idade|\n",
            "+------------+---------------------+-------------+-----------+\n",
            "|   MARKETING|                    2|       5100.0|       30.5|\n",
            "|          RH|                    3|       4800.0|       29.0|\n",
            "|DESCONHECIDA|                    1|       5500.0|       31.0|\n",
            "|  FINANCEIRO|                    4|       5750.0|      29.75|\n",
            "+------------+---------------------+-------------+-----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import functions as F\n",
        "\n",
        "# Calcular a rotatividade por departamento\n",
        "df_rotatividade = df.groupBy('Área') \\\n",
        "    .agg(F.count('Nome').alias('Contagem_Funcionários'),\n",
        "         F.round(F.avg('Salario'), 1).alias('Média_Salário'),\n",
        "         F.avg('Idade').alias('Média_Idade'))\n",
        "\n",
        "# Exibir o DataFrame com a rotatividade por departamento\n",
        "df_rotatividade.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "juiACAZYIbRt"
      },
      "source": [
        "### 42. Comparação de Salários por Gênero: Se houvesse uma coluna de gênero, comparar os salários médios entre homens e mulheres."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DRT9W8zSIvkF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f66340af-3057-40b8-8007-0ecc5d26306b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------------+\n",
            "|Gênero|Média_Salário|\n",
            "+------+-------------+\n",
            "|     F|       4880.0|\n",
            "|     M|       5740.0|\n",
            "+------+-------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import functions as F\n",
        "\n",
        "# Calcular a média de salário por gênero\n",
        "df_salario_genero = df.groupBy('Gênero') \\\n",
        "    .agg(F.mean('Salario').alias('Média_Salário'))\n",
        "\n",
        "# Exibir o DataFrame com a média de salário por gênero\n",
        "df_salario_genero.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-bUqphTIv5F"
      },
      "source": [
        "### 43. Correlação Entre Status de Emprego e Desempenho Salarial: Avaliar se há diferença significativa de salários entre diferentes status de emprego."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dtwe5-aQIzPr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb74a578-c248-4d4d-e3f1-5daa06780cc1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+-------------+\n",
            "|Status de Emprego|Média_Salário|\n",
            "+-----------------+-------------+\n",
            "|            ATIVO|       5200.0|\n",
            "|          INATIVO|       5750.0|\n",
            "+-----------------+-------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import functions as F\n",
        "\n",
        "# Calcular a média de salário por 'Status de Emprego'\n",
        "df_salario_status = df.groupBy('Status de Emprego') \\\n",
        "    .agg(F.mean('Salario').alias('Média_Salário')) \\\n",
        "    .orderBy('Status de Emprego')\n",
        "\n",
        "# Exibir o DataFrame com a média de salário por status de emprego\n",
        "df_salario_status.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2kPL9H8QIzh0"
      },
      "source": [
        "### 44. Análise de Impacto de Promoções: Se houvesse dados de promoções, analisar o impacto das promoções no salário ao longo do tempo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ff_dy6YDI2po",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "726a11d0-4074-448c-e05a-9c0633c5b207"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+-------------------+-------------+\n",
            "|          Nome|Data de Contratação|Média_Salário|\n",
            "+--------------+-------------------+-------------+\n",
            "|     Ana Clara|         12/06/2018|       4800.0|\n",
            "|Carlos Pereira|         01/04/2020|       6200.0|\n",
            "|  Fabio Santos|         20/11/2017|       5500.0|\n",
            "| Fernanda Dias|               NULL|       4800.0|\n",
            "|    José Alves|         01/02/2018|       5400.0|\n",
            "|    João Silva|         01/02/2020|       5500.0|\n",
            "| Luciana Costa|         01/01/2019|       5200.0|\n",
            "|   Maria Souza|         15/03/2019|       4800.0|\n",
            "| Paulo Ricardo|         12/12/2020|       6100.0|\n",
            "|   Sandra Lima|         05/05/2020|       4800.0|\n",
            "+--------------+-------------------+-------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import functions as F\n",
        "\n",
        "# Calcular a média de salário por 'Nome' e 'Data de Contratação'\n",
        "df_promocoes = df.groupBy('Nome', 'Data de Contratação') \\\n",
        "    .agg(F.mean('Salario').alias('Média_Salário')) \\\n",
        "    .orderBy('Nome', 'Data de Contratação')\n",
        "\n",
        "# Exibir o DataFrame com a média de salário por nome e data de contratação\n",
        "df_promocoes.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XErmUOI0I3BQ"
      },
      "source": [
        "### 45. Projeção de Custos Salariais: Calcular o custo projetado para a empresa em termos de salários nos próximos anos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rUjFM45YI6aq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "552ad1fe-eabf-44e5-bea5-967ec1375633"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------+----------------+\n",
            "|Custo_Total_2024|Custo_Total_2025|\n",
            "+----------------+----------------+\n",
            "|         55755.0|        58542.75|\n",
            "+----------------+----------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import functions as F\n",
        "\n",
        "# Definir o aumento percentual anual (por exemplo, 5%)\n",
        "aumento_percentual_anual = 0.05\n",
        "\n",
        "# Definir o número de anos para a projeção\n",
        "anos_projecao = 2\n",
        "\n",
        "# Calcular o custo projetado para os próximos 2 anos\n",
        "# A fórmula usada é: Salario * (1 + aumento_percentual_anual) ** anos_projecao\n",
        "\n",
        "df_projecao = df.withColumn(\n",
        "    'Custo_Projetado_2024',\n",
        "    F.col('Salario') * (1 + aumento_percentual_anual) ** 1\n",
        ").withColumn(\n",
        "    'Custo_Projetado_2025',\n",
        "    F.col('Salario') * (1 + aumento_percentual_anual) ** 2\n",
        ")\n",
        "\n",
        "# Calcular o custo total projetado para cada ano\n",
        "df_custo_total = df_projecao.select(\n",
        "    F.sum('Custo_Projetado_2024').alias('Custo_Total_2024'),\n",
        "    F.sum('Custo_Projetado_2025').alias('Custo_Total_2025')\n",
        ")\n",
        "\n",
        "# Exibir o custo total projetado para os próximos 2 anos\n",
        "df_custo_total.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IE7tgQ3EI64O"
      },
      "source": [
        "### 46. Análise de Desempenho por Escolaridade: Se houvesse uma coluna de escolaridade, analisar o impacto da escolaridade no salário."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m_MQWW4xI-Ki",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "870a697b-a82b-41b5-e1b4-2311a9f8de05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+-------------+\n",
            "|   Escolaridade|Média_Salário|\n",
            "+---------------+-------------+\n",
            "|Ensino Superior|       5740.0|\n",
            "|   Ensino Médio|       4880.0|\n",
            "+---------------+-------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import functions as F\n",
        "\n",
        "\n",
        "# Criar uma coluna  'Escolaridade' com valores aleatórios 'Ensino Médio' e 'Ensino Superior'\n",
        "df = df.withColumn('Escolaridade', F.when(df.ID % 2 == 0, 'Ensino Médio').otherwise('Ensino Superior'))\n",
        "\n",
        "# agrupar escolaridade dos funcionários por 'Salario'\n",
        "df_escolaridade_salario = df.groupBy('Escolaridade') \\\n",
        "    .agg(F.mean('Salario').alias('Média_Salário'))\n",
        "\n",
        "# Exibir o DataFrame com a média de salário por escolaridade\n",
        "df_escolaridade_salario.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNFsd_HlJA-q"
      },
      "source": [
        "### 47. Comparação Entre Funcionários com Benefícios: Se houvesse dados de benefícios, comparar o salário entre funcionários que recebem ou não benefícios."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v5BJBTKxJDJ2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ebf8c67-9e6e-442b-d6c1-94ec0958318d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-------------+\n",
            "|Beneficios|Média_Salário|\n",
            "+----------+-------------+\n",
            "|       Não|       4800.0|\n",
            "|       Sim|       5650.0|\n",
            "+----------+-------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import functions as F\n",
        "\n",
        "\n",
        "# Criar uma coluna de benefícios fictícia\n",
        "df = df.withColumn('Beneficios', when(df.Salario > 5000, 'Sim').otherwise('Não'))\n",
        "\n",
        "# Calcular a média de salário por benefício\n",
        "df_salario_beneficios = df.groupBy('Beneficios') \\\n",
        "    .agg(F.mean('Salario').alias('Média_Salário'))\n",
        "\n",
        "# Exibir o DataFrame com a média de salário por benefício\n",
        "df_salario_beneficios.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSoKMSEMJDle"
      },
      "source": [
        "### 48. Análise de Desempenho por Formação Acadêmica: Se houvesse uma coluna de formação, analisar como diferentes formações afetam o salário e tempo de casa."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qB0cmVNcJIjO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8cdaac2-666d-4b3c-cb14-4bf9a05f5f76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+-------------+-------------------+\n",
            "|   Escolaridade|Média_Salário|Média_Tempo_de_Casa|\n",
            "+---------------+-------------+-------------------+\n",
            "|Ensino Superior|       5740.0|  5.217999999999999|\n",
            "|   Ensino Médio|       4880.0|  5.425000000000001|\n",
            "+---------------+-------------+-------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import functions as F\n",
        "\n",
        "# Calcular a média de salário e tempo de casa por 'Escolaridade'\n",
        "df_escolaridade = df.groupBy('Escolaridade') \\\n",
        "    .agg(F.mean('Salario').alias('Média_Salário'),\n",
        "         F.mean('Tempo_de_Casa').alias('Média_Tempo_de_Casa'))\n",
        "\n",
        "# Exibir o DataFrame com a média de salário e tempo de casa por escolaridade\n",
        "df_escolaridade.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6oFtFwaJH2q"
      },
      "source": [
        "### 49. Previsão de Salários Futuros: Usar regressão linear ou outros modelos para prever o crescimento salarial futuro."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SYwzb8aYJMgi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2dbb4f98-45a6-4a8f-c542-74c410a28bbc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Tempo_de_Casa', 'Salario', 'Tempo_de_Casa_Imputed', 'features', 'prediction']\n",
            "+-------------+-------+-----------------+\n",
            "|Tempo_de_Casa|Salario|       prediction|\n",
            "+-------------+-------+-----------------+\n",
            "|         4.42| 6200.0|5331.977450253043|\n",
            "|         6.23| 4800.0|5190.082742260934|\n",
            "+-------------+-------+-----------------+\n",
            "\n",
            "Root Mean Squared Error (RMSE): 672.9144420648954\n"
          ]
        }
      ],
      "source": [
        "from pyspark.ml.regression import LinearRegression\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.feature import Imputer\n",
        "from pyspark.sql import functions as F\n",
        "# Selecionar as colunas relevantes para a previsão\n",
        "df_regressao = df.select('Tempo_de_Casa', 'Salario')\n",
        "\n",
        "# Lidar com valores nulos em 'Tempo_de_Casa' usando Imputer\n",
        "imputer = Imputer(inputCols=['Tempo_de_Casa'], outputCols=[\"Tempo_de_Casa_Imputed\"])\n",
        "df_regressao = imputer.fit(df_regressao).transform(df_regressao)\n",
        "\n",
        "# Criar um VectorAssembler para combinar as features em um único vetor\n",
        "assembler = VectorAssembler(inputCols=['Tempo_de_Casa_Imputed'], outputCol='features') # Use a coluna imputada\n",
        "df_regressao = assembler.transform(df_regressao)\n",
        "\n",
        "# Dividir os dados em conjuntos de treinamento e teste\n",
        "(training_data, test_data) = df_regressao.randomSplit([0.8, 0.2])\n",
        "\n",
        "# Criar um modelo de regressão linear\n",
        "lr = LinearRegression(featuresCol='features', labelCol='Salario')\n",
        "\n",
        "# Treinar o modelo com os dados de treinamento\n",
        "lr_model = lr.fit(training_data)\n",
        "\n",
        "# Fazer previsões com os dados de teste\n",
        "predictions = lr_model.transform(test_data)\n",
        "\n",
        "# Verificar se as colunas 'Salario' e 'prediction' estão presentes no DataFrame 'predictions'\n",
        "print(predictions.columns)\n",
        "\n",
        "# Exibir as previsões\n",
        "predictions.select('Tempo_de_Casa', 'Salario', 'prediction').show()\n",
        "\n",
        "# Avaliar o modelo\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "evaluator = RegressionEvaluator(labelCol='Salario', predictionCol='prediction', metricName='rmse')\n",
        "rmse = evaluator.evaluate(predictions)\n",
        "print(f'Root Mean Squared Error (RMSE): {rmse}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2oEgbw0JMvj"
      },
      "source": [
        "### 50. Identificação de Padrões de Promoção Interna: Analisar os padrões de promoção dentro da empresa ao longo dos anos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mkd5ZIYuJQHy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0962c6f-b60a-491d-f264-92294eff9883"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---------------+----------------------+---------------+-------------------+---------------------+\n",
            "| ID| Cargo_Anterior|Data_Promocao_Anterior|    Cargo_Atual|Data_Promocao_Atual|Tempo_Entre_Promocoes|\n",
            "+---+---------------+----------------------+---------------+-------------------+---------------------+\n",
            "|  1|       Analista|            2020-01-15|Analista Senior|         2022-06-20|                  887|\n",
            "|  2|       Analista|            2021-03-10|   Especialista|         2023-09-15|                  919|\n",
            "|  3|        Gerente|            2019-05-05| Gerente Senior|         2021-12-01|                  941|\n",
            "|  1|Analista Senior|            2022-06-20|        Gerente|         2023-11-10|                  508|\n",
            "+---+---------------+----------------------+---------------+-------------------+---------------------+\n",
            "\n",
            "Tempo médio entre promoções: 813.75 dias\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import functions as F\n",
        "# Criar um DataFrame com dados de promoção simulados\n",
        "df_promocoes = spark.createDataFrame([\n",
        "    (1, 'Analista', '2020-01-15', 'Analista Senior', '2022-06-20'),\n",
        "    (2, 'Analista', '2021-03-10', 'Especialista', '2023-09-15'),\n",
        "    (3, 'Gerente', '2019-05-05', 'Gerente Senior', '2021-12-01'),\n",
        "    (1, 'Analista Senior', '2022-06-20', 'Gerente', '2023-11-10')\n",
        "], ['ID', 'Cargo_Anterior', 'Data_Promocao_Anterior', 'Cargo_Atual', 'Data_Promocao_Atual'])\n",
        "\n",
        "# Calcular o tempo entre as promoções\n",
        "df_promocoes = df_promocoes.withColumn(\n",
        "    'Tempo_Entre_Promocoes',\n",
        "    F.datediff(F.to_date('Data_Promocao_Atual'), F.to_date('Data_Promocao_Anterior'))\n",
        ")\n",
        "\n",
        "# Exibir o DataFrame com o tempo entre as promoções\n",
        "df_promocoes.show()\n",
        "\n",
        "# Analisar os padrões de promoção (exemplo: tempo médio entre promoções)\n",
        "tempo_medio_promocoes = df_promocoes.agg(F.mean('Tempo_Entre_Promocoes')).collect()[0][0]\n",
        "\n",
        "# Exibir o tempo médio entre promoções\n",
        "print(f'Tempo médio entre promoções: {tempo_medio_promocoes} dias')\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}